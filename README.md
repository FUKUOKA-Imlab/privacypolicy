### We are conducting research on the theme of robot arm operation using facial expressions. This document is intended to explain the purpose, method, and points to note of the experiment to those who plan to participate in this experiment as experimental collaborators. Please read this explanation about the experiment, fully understand the contents, and freely decide whether to cooperate with the experiment.

### 1. Purpose
##### In the robot arm operation using facial expressions, in order to measure whether a sense of agency is generated, the facial expression is recognized using the camera mounted on the smartphone, and the 3DCG robot arm displayed on the smartphone screen is operated. In addition, we will conduct a questionnaire survey on the perception of sound generated in relation to arm operation.

### 2. Contents of cooperation
##### We ask the perticipants to install the application on their smartphone devices and cooperate with the data collection. The specific details are as follows.
##### (1) Open and close the mouth according to the instructions on the display.
##### (2) Listen to the two consecutive sounds presented and answer the questionnaire as to which sound is louder.

### 3. Possible risks
##### 3D motion sickness may occur due to the movement of the robot arm displayed on the screen. If you feel tired during the experiment, stop the experiment immediately.

### 4. If you do not agree with the research cooperation
##### There is no penalty for not agreeing to participate in the experiment.

### 5. Withdrawal of consent for research cooperation
##### Even if you agree to participate in the experiment, you can cancel the experiment at any time for any reason. There are no disadvantages due to withdrawing from participation.

### 6. Protection of personal information
##### In the experiment, we record the questionnaire result and Face Anchor information according to the experiment item for each individual. Face Anchor information is data obtained by dividing the face into 52 parts and converting the degree of deformation of each part to 0.0-1.0, and does not identify an individual. After the experiment, the individual names of the participants will be anonymized and saved and analyzed. When anonymizing, the experiment participants will be represented by symbols, etc., and the correspondence table for anonymization that can confirm the correspondence between individual names and symbols will be accessible only to the experimenters. In addition, personal names will not be disclosed even if we decided to publish in academic conferences or in academic papers.

### 7. Regarding face image recording/analysis/publication
##### After the experiment, the acquired questionnaire results and Face Anchor information will be used for recording and analysis in the laboratory, and will be published in presentation materials and academic papers. As a usage method, the results of a questionnaire about the loudness of sounds are tabulated on slides and papers for each condition, and then anonymized. Face Anchor information is not used as individual data, but is used to identify the tendency of the face part used when operating the robot arm as a whole. If there is a request for refusal of publication after implementation, the survey results and Face Anchor information will not be published. In addition, there is no disadvantage caused by not agreeing to record, analyze and publish face anchors. 

### 8. Handling policy for data and samples after research
##### The measured data will not be saved on paper and will be managed on a server outsourced by Keio University that requires account authentication and on a computer used for experiments and analysis. If you wish to dispose of it, we delete it immediately from the server and computer.

### 9. Cost of this research
##### This research is supported by JST ERATO JPMJER1701. 

### 10. Contact information
##### Representative:Maki Sugimoto at Keio University, 3-14-1 Hiyoshi, Kohoku-ku, Yokohama-shi, Kanagawa 223-8522 Japan
##### Person in charge:Masaki Fukuoka; Email:mskifukuoka[at]imlab.ics.keio.ac.jp 
